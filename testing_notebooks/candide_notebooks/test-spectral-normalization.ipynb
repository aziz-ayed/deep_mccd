{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING\u001b[0m: Using pyFFTW \"monkey patch\" for scipy.fftpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runstats and/or skimage could not be imported because not installed\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "2.4.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mccd\n",
    "from astropy.io import fits\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Layer, Conv2D, LeakyReLU, PReLU, UpSampling2D, MaxPooling2D, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_addons.layers import SpectralNormalization\n",
    "\n",
    "class Conv(Layer):\n",
    "    def __init__(self, n_filters, kernel_size=3, non_linearity='relu', spectral_normalization=False, power_iterations=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.non_linearity = non_linearity\n",
    "        self.spectral_normalization = spectral_normalization\n",
    "        self.power_iterations = power_iterations\n",
    "        if self.spectral_normalization:\n",
    "            self.conv = SpectralNormalization(\n",
    "                Conv2D(\n",
    "                    filters=self.n_filters,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    padding='same',\n",
    "                    activation=None,\n",
    "                ),\n",
    "                power_iterations=self.power_iterations,\n",
    "            )\n",
    "        else:\n",
    "            self.conv = Conv2D(\n",
    "                filters=self.n_filters,\n",
    "                kernel_size=self.kernel_size,\n",
    "                padding='same',\n",
    "                activation=None,\n",
    "            )\n",
    "        if self.non_linearity == 'lrelu':\n",
    "            self.act = LeakyReLU(0.1)\n",
    "        elif self.non_linearity == 'prelu':\n",
    "            self.act = PReLU(shared_axes=[1, 2])\n",
    "        else:\n",
    "            self.act = Activation(self.non_linearity)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.conv(inputs)\n",
    "        outputs = self.act(outputs)\n",
    "        return outputs\n",
    "\n",
    "class ConvBlock(Layer):\n",
    "    def __init__(self, n_filters, kernel_size=3, non_linearity='relu', n_non_lins=2, spectral_normalization=False, power_iterations=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.non_linearity = non_linearity\n",
    "        self.n_non_lins = n_non_lins\n",
    "        self.spectral_normalization = spectral_normalization\n",
    "        self.power_iterations = power_iterations\n",
    "        self.convs = [\n",
    "            Conv(\n",
    "                n_filters=self.n_filters,\n",
    "                kernel_size=self.kernel_size,\n",
    "                non_linearity=self.non_linearity,\n",
    "                spectral_normalization=self.spectral_normalization,\n",
    "                power_iterations=self.power_iterations,\n",
    "            ) for _ in range(self.n_non_lins)\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        for conv in self.convs:\n",
    "            outputs = conv(outputs)\n",
    "        return outputs\n",
    "\n",
    "class UpConv(Layer):\n",
    "    def __init__(self, n_filters, kernel_size=3, spectral_normalization=False, power_iterations=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.spectral_normalization = spectral_normalization\n",
    "        self.power_iterations = power_iterations\n",
    "        if self.spectral_normalization:\n",
    "            self.conv = SpectralNormalization(\n",
    "                Conv2D(\n",
    "                    filters=self.n_filters,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    padding='same',\n",
    "                    activation=None,\n",
    "                ),\n",
    "                power_iterations=self.power_iterations,\n",
    "            )\n",
    "        else:\n",
    "            self.conv = Conv2D(\n",
    "                filters=self.n_filters,\n",
    "                kernel_size=self.kernel_size,\n",
    "                padding='same',\n",
    "                activation=None,\n",
    "            )\n",
    "        self.up = UpSampling2D(size=(2, 2))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.up(inputs)\n",
    "        outputs = self.conv(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class Unet(Model):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_output_channels=1,\n",
    "            kernel_size=3,\n",
    "            layers_n_channels=[64, 128, 256, 512, 1024],\n",
    "            layers_n_non_lins=2,\n",
    "            non_linearity='relu',\n",
    "            spectral_normalization=False,\n",
    "            power_iterations=5,\n",
    "            **kwargs,\n",
    "        ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_output_channels = n_output_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.layers_n_channels = layers_n_channels\n",
    "        self.n_layers = len(self.layers_n_channels)\n",
    "        self.spectral_normalization = spectral_normalization\n",
    "        self.layers_n_non_lins = layers_n_non_lins\n",
    "        self.non_linearity = non_linearity\n",
    "        self.power_iterations = power_iterations\n",
    "        self.down_convs = [\n",
    "            ConvBlock(\n",
    "                n_filters=n_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                non_linearity=self.non_linearity,\n",
    "                n_non_lins=self.layers_n_non_lins,\n",
    "                spectral_normalization=self.spectral_normalization,\n",
    "                power_iterations=self.power_iterations,\n",
    "            ) for n_channels in self.layers_n_channels[:-1]\n",
    "        ]\n",
    "        self.down = MaxPooling2D(pool_size=(2, 2), padding='same')\n",
    "        self.bottom_conv = ConvBlock(\n",
    "            n_filters=self.layers_n_channels[-1],\n",
    "            kernel_size=self.kernel_size,\n",
    "            non_linearity=self.non_linearity,\n",
    "            n_non_lins=self.layers_n_non_lins,\n",
    "            spectral_normalization=self.spectral_normalization,\n",
    "            power_iterations=self.power_iterations,\n",
    "        )\n",
    "        self.up_convs = [\n",
    "            ConvBlock(\n",
    "                n_filters=n_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                non_linearity=self.non_linearity,\n",
    "                n_non_lins=self.layers_n_non_lins,\n",
    "                spectral_normalization=self.spectral_normalization,\n",
    "                power_iterations=self.power_iterations,\n",
    "            ) for n_channels in self.layers_n_channels[:-1]\n",
    "        ]\n",
    "        self.ups = [\n",
    "            UpConv(\n",
    "                n_filters=n_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                spectral_normalization=self.spectral_normalization,\n",
    "                power_iterations=self.power_iterations,\n",
    "            ) for n_channels in self.layers_n_channels[:-1]\n",
    "        ]\n",
    "        if self.spectral_normalization:            \n",
    "            self.final_conv = SpectralNormalization(\n",
    "                Conv2D(\n",
    "                    filters=self.n_output_channels,\n",
    "                    kernel_size=1,\n",
    "                    padding='same',\n",
    "                    activation=None,\n",
    "                ),\n",
    "                power_iterations=self.power_iterations,\n",
    "            )    \n",
    "        else:\n",
    "            self.final_conv = Conv2D(\n",
    "                filters=self.n_output_channels,\n",
    "                kernel_size=1,\n",
    "                padding='same',\n",
    "                activation=None,\n",
    "            )\n",
    "        \n",
    "    def pad(self, image):\n",
    "        r\"\"\"Convert images to 64x64x1 shaped tensors to feed the model, using zero-padding.\"\"\"\n",
    "        pad = tf.constant([[0,0], [6,7],[6,7], [0,0]])\n",
    "        return tf.pad(image, pad, \"CONSTANT\")    \n",
    "        \n",
    "    def crop(self, image):\n",
    "        r\"\"\"Crop back the image to its original size and convert it to np.array\"\"\"\n",
    "        return tf.image.crop_to_bounding_box(image, 6, 6, 51, 51)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        scales = []\n",
    "        outputs = self.pad(inputs)\n",
    "        for conv in self.down_convs:\n",
    "            outputs = conv(outputs)\n",
    "            scales.append(outputs)\n",
    "            outputs = self.down(outputs)\n",
    "        outputs = self.bottom_conv(outputs)\n",
    "        for scale, conv, up in zip(scales[::-1], self.up_convs[::-1], self.ups[::-1]):\n",
    "            outputs = up(outputs)\n",
    "            outputs = tf.concat([outputs, scale], axis=-1)\n",
    "            outputs = conv(outputs)\n",
    "        outputs = self.final_conv(outputs)\n",
    "        outputs = self.crop(outputs)\n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mccd.denoising.evaluate import keras_psnr, center_keras_psnr\n",
    "from mccd.denoising.preprocessing import eigenPSF_data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12G\n",
      "drwxrwxr-x 2 tliaudat tliaudat  105 Feb 22 14:27 .\n",
      "drwxrwxr-x 9 tliaudat tliaudat  251 Feb 22 13:46 ..\n",
      "-rw-rw-r-- 1 tliaudat tliaudat 5.9G Feb 22 14:27 all_eigenpsfs.fits\n",
      "-rw-rw-r-- 1 tliaudat tliaudat 447M Feb 22 14:27 global_eigenpsfs.fits\n",
      "-rw-rw-r-- 1 tliaudat tliaudat 5.5G Feb 22 14:27 local_eigenpsfs.fits\n"
     ]
    }
   ],
   "source": [
    "!ls -lah /n05data/tliaudat/new_deepmccd/training_realistic_sims/output_mccd/eigenPSF_datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n",
      "Load data..\n",
      "Prepare datasets..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = {\n",
    "    'run_id_name': 'spec_norm_unet',\n",
    "    'dataset_path': '/n05data/tliaudat/new_deepmccd/training_realistic_sims/output_mccd/eigenPSF_datasets/local_eigenpsfs.fits',\n",
    "    'base_save_path': '/n05data/tliaudat/new_deepmccd/sandbox/testing_spectral_norm/',\n",
    "    'batch_size': 32,\n",
    "    'data_train_ratio': 0.8,\n",
    "    'n_epochs': 100,\n",
    "    'lr_param': 1e-3,\n",
    "    'use_lr_scheduler': True,\n",
    "    'layers_n_channel': 64,\n",
    "    'layers_levels': 5,\n",
    "    'kernel_size': 3,\n",
    "    'n_shuffle': 50,\n",
    "    'spectral_normalization': True,\n",
    "    'power_iterations': 1,\n",
    "}\n",
    "\n",
    "# Paths\n",
    "run_id_name = args['run_id_name']\n",
    "eigenpsf_dataset_path = args['dataset_path']\n",
    "base_save_path = args['base_save_path']\n",
    "checkpoint_path = base_save_path + 'cp_' + run_id_name + '.h5'\n",
    "\n",
    "# Save parameters\n",
    "# np.save(base_save_path + 'params_' + run_id_name + '.npy', args, allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "batch_size = args['batch_size'] # 32\n",
    "n_epochs = args['n_epochs'] # 500\n",
    "lr_param =  args['lr_param'] # 1e-3\n",
    "\n",
    "\n",
    "\n",
    "# Unet parameters\n",
    "\n",
    "# # Save output prints to logfile\n",
    "# old_stdout = sys.stdout\n",
    "# log_file = open(base_save_path + run_id_name + '_output.log','w')\n",
    "# sys.stdout = log_file\n",
    "# print('Starting the log file.')\n",
    "\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "print('Load data..')\n",
    "img = fits.open(eigenpsf_dataset_path)\n",
    "img = img[1].data['VIGNETS_NOISELESS']\n",
    "\n",
    "np.random.shuffle(img)\n",
    "\n",
    "size_train = np.floor(len(img) * args['data_train_ratio'])\n",
    "training, test = img[:int(size_train),:,:], img[int(size_train):,:,:]\n",
    "\n",
    "print('Prepare datasets..')\n",
    "training = eigenPSF_data_gen(\n",
    "    data=training,\n",
    "    snr_range= [1e-3, 100],\n",
    "    img_shape=(51, 51),\n",
    "    batch_size=batch_size,\n",
    "    n_shuffle=args['n_shuffle'],\n",
    "    noise_estimator=False,\n",
    "    enhance_noise=True,\n",
    ")\n",
    "\n",
    "test = eigenPSF_data_gen(\n",
    "    data=test,\n",
    "    snr_range= [1e-3, 100],\n",
    "    img_shape=(51, 51),\n",
    "    batch_size=1,\n",
    "    noise_estimator=False,\n",
    "    enhance_noise=True,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers_n_channels:  [64, 128, 256, 512, 1024]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "steps = int(size_train/batch_size)\n",
    "\n",
    "# Increasing the filter number with a factor of 2\n",
    "layers_n_channels = [args['layers_n_channel'] * (2**it) for it in range(args['layers_levels'])]\n",
    "print('layers_n_channels: ', layers_n_channels)\n",
    "\n",
    "model = Unet(\n",
    "    n_output_channels=1,\n",
    "    kernel_size=args['kernel_size'],\n",
    "    layers_n_channels=layers_n_channels,\n",
    "    spectral_normalization=args['spectral_normalization'],\n",
    "    power_iterations=args['power_iterations'],\n",
    ")    \n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='mse',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    save_freq='epoch',\n",
    "    options=None\n",
    ")\n",
    "\n",
    "def l_rate_schedule(epoch):\n",
    "    return max(1e-3 / 2**(epoch//25), 1e-5)\n",
    "lr_cback = tf.keras.callbacks.LearningRateScheduler(l_rate_schedule)\n",
    "\n",
    "if args['use_lr_scheduler']:\n",
    "    models_callbacks = [cp_callback, lr_cback]\n",
    "else:\n",
    "    models_callbacks = [cp_callback]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_param),\n",
    "    loss='mse',\n",
    "    metrics=['mse', keras_psnr, center_keras_psnr],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training and timing..\n",
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 527s 75ms/step - loss: 9.4318e-04 - mse: 9.4318e-04 - keras_psnr: 37.9206 - center_keras_psnr: 35.7359 - val_loss: 0.0107 - val_mse: 0.0107 - val_keras_psnr: 19.7256 - val_center_keras_psnr: 19.7838\n",
      "\n",
      "Epoch 00001: mse improved from inf to 0.00051, saving model to /n05data/tliaudat/new_deepmccd/sandbox/testing_spectral_norm/cp_spec_norm_unet.h5\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 522s 75ms/step - loss: 2.9128e-04 - mse: 2.9128e-04 - keras_psnr: 41.2440 - center_keras_psnr: 39.0368 - val_loss: 3.7991e-05 - val_mse: 3.7991e-05 - val_keras_psnr: 44.2032 - val_center_keras_psnr: 42.3666\n",
      "\n",
      "Epoch 00002: mse improved from 0.00051 to 0.00021, saving model to /n05data/tliaudat/new_deepmccd/sandbox/testing_spectral_norm/cp_spec_norm_unet.h5\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 522s 75ms/step - loss: 1.8423e-04 - mse: 1.8423e-04 - keras_psnr: 43.0368 - center_keras_psnr: 41.0440 - val_loss: 0.0024 - val_mse: 0.0024 - val_keras_psnr: 26.2139 - val_center_keras_psnr: 26.9798\n",
      "\n",
      "Epoch 00003: mse improved from 0.00021 to 0.00017, saving model to /n05data/tliaudat/new_deepmccd/sandbox/testing_spectral_norm/cp_spec_norm_unet.h5\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 522s 75ms/step - loss: 1.6004e-04 - mse: 1.6004e-04 - keras_psnr: 43.7887 - center_keras_psnr: 41.8939 - val_loss: 1.8800e-04 - val_mse: 1.8800e-04 - val_keras_psnr: 37.2584 - val_center_keras_psnr: 36.4391\n",
      "\n",
      "Epoch 00004: mse improved from 0.00017 to 0.00017, saving model to /n05data/tliaudat/new_deepmccd/sandbox/testing_spectral_norm/cp_spec_norm_unet.h5\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 523s 75ms/step - loss: 1.4655e-04 - mse: 1.4655e-04 - keras_psnr: 43.7736 - center_keras_psnr: 41.9354 - val_loss: 4.8599e-06 - val_mse: 4.8599e-06 - val_keras_psnr: 53.1337 - val_center_keras_psnr: 52.5535\n",
      "\n",
      "Epoch 00005: mse improved from 0.00017 to 0.00015, saving model to /n05data/tliaudat/new_deepmccd/sandbox/testing_spectral_norm/cp_spec_norm_unet.h5\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 521s 74ms/step - loss: 1.5854e-04 - mse: 1.5854e-04 - keras_psnr: 44.0065 - center_keras_psnr: 42.2282 - val_loss: 1.3434e-05 - val_mse: 1.3434e-05 - val_keras_psnr: 48.7179 - val_center_keras_psnr: 47.9124\n",
      "\n",
      "Epoch 00006: mse did not improve from 0.00015\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 522s 75ms/step - loss: 1.3862e-04 - mse: 1.3862e-04 - keras_psnr: 44.1247 - center_keras_psnr: 42.3251 - val_loss: 3.2200e-05 - val_mse: 3.2200e-05 - val_keras_psnr: 44.9215 - val_center_keras_psnr: 44.0302\n",
      "\n",
      "Epoch 00007: mse improved from 0.00015 to 0.00014, saving model to /n05data/tliaudat/new_deepmccd/sandbox/testing_spectral_norm/cp_spec_norm_unet.h5\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 523s 75ms/step - loss: 1.4125e-04 - mse: 1.4125e-04 - keras_psnr: 44.5911 - center_keras_psnr: 42.7781 - val_loss: 1.0986e-04 - val_mse: 1.0986e-04 - val_keras_psnr: 39.5917 - val_center_keras_psnr: 39.1921\n",
      "\n",
      "Epoch 00008: mse did not improve from 0.00014\n",
      "Epoch 9/100\n",
      "6930/7000 [============================>.] - ETA: 5s - loss: 1.3408e-04 - mse: 1.3408e-04 - keras_psnr: 44.2238 - center_keras_psnr: 42.5629"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8c1efc79d43d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model training ended..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/softs/python/py3mods/tensorflow/2.4.4/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Start model training and timing..')\n",
    "start_train = time.time()\n",
    "history = model.fit(\n",
    "    training,\n",
    "    validation_data=test,\n",
    "    steps_per_epoch=steps,\n",
    "    epochs=n_epochs,\n",
    "    validation_steps=1,\n",
    "    callbacks=models_callbacks,\n",
    "    shuffle=False,\n",
    "    verbose=1,\n",
    ")\n",
    "print('Model training ended..')\n",
    "end_train = time.time()\n",
    "print('Train elapsed time: %f'%(end_train-start_train))\n",
    "\n",
    "# Save history file\n",
    "try:\n",
    "    np.save(base_save_path + run_id_name + '_history_file.npy', history.history, allow_pickle=True)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "UNET 32\n",
    "With power_iterations=10\n",
    "- One epoch is ~380s\n",
    "\n",
    "With power_iterations=5\n",
    "- One epoch is  ~309s\n",
    "\n",
    "With power_iterations=1\n",
    "- One epoch is  ~242s\n",
    "\n",
    "UNET 64\n",
    "With power_iterations=1\n",
    "- One epoch is  ~522s\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
